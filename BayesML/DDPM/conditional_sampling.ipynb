{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!if [ -d HSE ]; then rm -Rf HSE; fi\n",
        "!git clone https://github.com/Tikhon239/HSE\n",
        "!cp -a /content/HSE/BayesML/DDPM/* ."
      ],
      "metadata": {
        "id": "eBVd-vFHINGa"
      },
      "id": "eBVd-vFHINGa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install wandb\n",
        "!pip3 install ml_collections"
      ],
      "metadata": {
        "id": "scyFkZf9Iku2"
      },
      "id": "scyFkZf9Iku2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 train_ddpm_cont.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JoOzS6zTId5g",
        "outputId": "5506bc6d-bee4-4325-c40f-80fdc4d377ff"
      },
      "id": "JoOzS6zTId5g",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshytea\u001b[0m (use `wandb login --relogin` to force relogin)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.14\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20220413_192453-brkz0jzs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mddpm_cont\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/shytea/sde\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/shytea/sde/runs/brkz0jzs\u001b[0m\n",
            " 56% 2794/5000 [1:07:04<49:20,  1.34s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Network error (ReadTimeout), entering retry loop.\n",
            "100% 5000/5000 [2:01:00<00:00,  1.45s/it]\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        loss/train ‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: loss/valid_loader ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          lr/train ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        loss/train 18.64536\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: loss/valid_loader 16.84673\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          lr/train 0.0002\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mddpm_cont\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/shytea/sde/runs/brkz0jzs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 10 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220413_192453-brkz0jzs/logs\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 train_noisy_classifier.py"
      ],
      "metadata": {
        "id": "HS1usvK3av2R"
      },
      "id": "HS1usvK3av2R",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ecf2c13",
      "metadata": {
        "id": "7ecf2c13"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import wandb\n",
        "import torchvision\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from data_generator import DataGenerator\n",
        "from default_mnist_config import create_default_mnist_config\n",
        "from diffusion import DiffusionRunner\n",
        "from models.classifier import ResNet, ResidualBlock, ConditionalResNet\n",
        "\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d689c2b9",
      "metadata": {
        "id": "d689c2b9",
        "outputId": "08bae0f6-6dbf-4c69-fc28-33b2f92ba85b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device('cuda')\n",
        "classifier_args = {\n",
        "    \"block\": ResidualBlock,\n",
        "    \"layers\": [2, 2, 2, 2]\n",
        "}\n",
        "noisy_classifier = ConditionalResNet(**classifier_args)\n",
        "noisy_classifier.to(device)\n",
        "\n",
        "noisy_classifier.load_state_dict(torch.load('./ddpm_checkpoints/classifier.pth'))\n",
        "\n",
        "clean_classifier = ResNet(**classifier_args)\n",
        "clean_classifier.to(device)\n",
        "\n",
        "clean_classifier.load_state_dict(torch.load('./ddpm_checkpoints/clean_classifier.pth'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d9ff044",
      "metadata": {
        "id": "4d9ff044"
      },
      "source": [
        "#### –°–æ–∑–¥–∞–π—Ç–µ –¥–≤–∞ —Å–µ–º–ø–ª–µ–º–µ—Ä–∞ –∫–∞—Ä—Ç–∏–Ω–æ–∫, –±–µ–∑—É—Å–ª–æ–≤–Ω—ã–π –∏ —É—Å–ª–æ–≤–Ω—ã–π —Å –º–µ—Ç–æ–¥–æ–º .set_classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15197a37",
      "metadata": {
        "scrolled": true,
        "id": "15197a37"
      },
      "outputs": [],
      "source": [
        "conditional_diffusion = DiffusionRunner(create_default_mnist_config(), eval=True)\n",
        "conditional_diffusion.set_classifier(noisy_classifier, T=1.)\n",
        "\n",
        "unconditional_diffusion = DiffusionRunner(create_default_mnist_config(), eval=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0161c142",
      "metadata": {
        "id": "0161c142"
      },
      "outputs": [],
      "source": [
        "def get_pred_labels(images_normed: torch.Tensor):\n",
        "    \"\"\"\n",
        "    predict labels for normed images \n",
        "    [-1, 1]\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "def calc_acc_clean_classifier(images_normed: torch.Tensor, labels: torch.Tensor):\n",
        "    \"\"\"\n",
        "    calculate accuracy using clean classifier\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "def sample_images(diff_process, labels=None):\n",
        "    images_tensor = diff_process.sample_images(batch_size=100, labels=labels)\n",
        "    images_cpu = images_tensor.cpu()\n",
        "    grid = torchvision.utils.make_grid(images_cpu, nrow=10).permute(1, 2, 0)\n",
        "    grid = grid.data.numpy().astype(np.uint8)\n",
        "\n",
        "    plt.imshow(grid)\n",
        "    plt.show()\n",
        "    return images_tensor\n",
        "\n",
        "\n",
        "def cond_print_and_calc_acc(class_num: int):\n",
        "    labels = class_num*torch.ones(100).long().to(device)\n",
        "    images_tensor = sample_images(conditional_diffusion, labels)\n",
        "    acc = calc_acc_clean_classifier((images_tensor - 127.5)/ 127.5, labels=labels)\n",
        "    print('Accuracy: ', acc.item())\n",
        "    return images_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3698a95",
      "metadata": {
        "id": "e3698a95"
      },
      "source": [
        "#### –ü–æ—Å–µ–º–ø–ª–∏—Ä—É–π—Ç–µ –Ω–∞–±–æ—Ä—ã –∫–∞—Ä—Ç–∏–Ω–æ–∫ –≤—Å–µ—Ö –∫–ª–∞—Å—Å–æ–≤ –æ–±–æ–∏–º–∏ —Å–ø–æ—Å–æ–±–∞–º–∏, –∏–∑–º–µ–Ω–∏—Ç—å —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É –º–æ–∂–Ω–æ —Å –ø–æ–º–æ—â—å—é –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ .set_classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e999d5a8",
      "metadata": {
        "id": "e999d5a8"
      },
      "source": [
        "> –ö–∞–∫ —Å–∏–ª—å–Ω–æ –≤–ª–∏—è–µ—Ç —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –Ω–∞ –æ—Ç–ª–∏—á–∏–º–æ—Å—Ç—å —Å–µ–º–ø–ª–æ–≤ –ø—Ä–∏ —É—Å–ª–æ–≤–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏? –ü—Ä–æ–¥–µ–º–µ–Ω—Å—Ç—Ä–∏—Ä—É–π—Ç–µ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö T —Å–≤–æ–∏ –≤—ã–≤–æ–¥—ã.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62ce953c",
      "metadata": {
        "id": "62ce953c"
      },
      "source": [
        "> –ö–∞–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –ø–æ–ª—É—á–∞–µ—Ç—Å—è —É —á–∏—Å—Ç–æ–≥–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ –ø—Ä–∏ —É—Å–ª–æ–≤–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏? –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –æ—Ü–µ–Ω–∏—Ç—å –Ω–∞ –≥–ª–∞–∑ –∫–∞—á–µ—Å—Ç–≤–æ —á–∏—Å—Ç–æ–≥–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ –¥–ª—è –±–µ–∑—É—Å–ª–æ–≤–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏, –æ–±—ä—è—Å–Ω–∏—Ç–µ —Å–≤–æ–∏ –≤—ã–≤–æ–¥—ã.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "colab": {
      "name": "conditional_sampling.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}